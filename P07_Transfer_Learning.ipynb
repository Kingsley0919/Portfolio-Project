{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD4xqavfrauc"
      },
      "source": [
        "#**Transfer Learning**\n",
        "\n",
        "**Reference**: Deep Learning for Data Science (BCS, FICT)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyqpElym-dXl"
      },
      "source": [
        "**Why do we need Transfer Learning?**\n",
        "* Saving effort to train a model from scratch\n",
        "* Transfer learning reduces overfitting and improves the generalization performance (especially when the training set for the targeted task is small)\n",
        "\n",
        "\n",
        "In practice, it is common to use a **CNN architectures** such that ResNet, MNASNet, ResNeXt, EfficientNet, etc. to build a model. The effectiveness of these network architectures has been well attested for a wide range of applications.  The [`torchvision.models`](https://pytorch.org/vision/stable/models.html) package contains these different network models that have been pre-trained on ImageNet.\n",
        "\n",
        "In general, there are two ways to perform transfer learning:\n",
        "\n",
        "1. **Finetuning the entire network**: Instead of random initialization,  initialize the network with the pretrained network.\n",
        "\n",
        "2. **Fixed feature extractor**: Freeze the weights for all of the layers of the network except for the final fully connected (fc) layer. Replace the last fc layer so that the output size is the same as the number of classes for the new task. The new layer is initialized with random weights and only this layer is trained.\n",
        "\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "To train a pretrain model by:\n",
        "1. Training from scratch (without pretrained weights)\n",
        "2. Finetuning the entire pretrained model\n",
        "3. Finetuning the upper (last few) layers of the pretrained model\n",
        "4. Finetuning only the fc layers (fixed feature extractor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remember** to enable the GPU for this notebook before we start:\n",
        "\n",
        "1. by setting `Edit` >\n",
        "`Notebook settings` > `Hardware accelerator` to `GPU` or,\n",
        "\n",
        "2. by setting `Runtime` > `Change Runtime Type`> `Hardward Accelerator` to `GPU`."
      ],
      "metadata": {
        "id": "dAA7VzBZY2on"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2KWVeVT-dXv"
      },
      "source": [
        "Mount google drive onto virtual machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0wMiAU9V-dX2",
        "outputId": "4e0d50cc-3743-4057-d96b-93049a32a53a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jWdhHmts-dYF",
        "outputId": "63739ab9-b689-4212-efd2-8fb141e5b077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/PDL_2023\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/gdrive/MyDrive/PDL_2023\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir P07\n",
        "%cd ./P07"
      ],
      "metadata": {
        "id": "yZl5hIagIW84",
        "outputId": "d849ba72-1eee-45fd-e5da-890bbd1b8627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘P07’: File exists\n",
            "/content/gdrive/MyDrive/PDL_2023/P07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the helper function to load data"
      ],
      "metadata": {
        "id": "QbK4vmbdQ0Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the cifar10 function from google drive\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1OgEoKomios7ZLSQGlG4NJHrH_mIGYK98/view?usp=sharing"
      ],
      "metadata": {
        "id": "N5XOu_s5QzXt",
        "outputId": "2eaf41f9-138d-4689-bbf6-be5be1eb6fff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1OgEoKomios7ZLSQGlG4NJHrH_mIGYK98\n",
            "From (redirected): https://drive.google.com/uc?id=1OgEoKomios7ZLSQGlG4NJHrH_mIGYK98&confirm=t&uuid=ce4a6e40-40b5-4b37-b9f1-d2086b125a49\n",
            "To: /content/gdrive/MyDrive/PDL_2023/P07/cifar10.py\n",
            "\r  0% 0.00/1.48k [00:00<?, ?B/s]\r100% 1.48k/1.48k [00:00<00:00, 7.32MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMc8XRwD-dYT"
      },
      "source": [
        "Load required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NgG6mM_c-dYY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from cifar10 import CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23H6bUc4-dY5"
      },
      "source": [
        "---\n",
        "## Helper Functions\n",
        "\n",
        "Define the train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0G9F-olF-dY8"
      },
      "outputs": [],
      "source": [
        "loss_iter = 1\n",
        "\n",
        "def train(net, num_epochs, lr=0.1, momentum=0.9, verbose=True):\n",
        "\n",
        "    history = []\n",
        "\n",
        "    loss_iterations = int(np.ceil(len(trainloader)/loss_iter))\n",
        "\n",
        "    # transfer model to GPU\n",
        "    if torch.cuda.is_available():\n",
        "        net = net.cuda()\n",
        "\n",
        "    # set the optimizer\n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    # set to training mode\n",
        "    net.train()\n",
        "\n",
        "    # train the network\n",
        "    for e in range(num_epochs):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_count = 0.0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "            # Clear all the gradient to 0\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # transfer data to GPU\n",
        "            if torch.cuda.is_available():\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            # forward propagation to get h\n",
        "            outs = net(inputs)\n",
        "\n",
        "            # compute loss\n",
        "            loss = F.cross_entropy(outs, labels)\n",
        "\n",
        "            # backpropagation to get dw\n",
        "            loss.backward()\n",
        "\n",
        "            # update w\n",
        "            optimizer.step()\n",
        "\n",
        "            # get the loss\n",
        "            running_loss += loss.item()\n",
        "            running_count += 1\n",
        "\n",
        "             # display the averaged loss value\n",
        "            if i % loss_iterations == loss_iterations-1 or i == len(trainloader) - 1:\n",
        "                train_loss = running_loss / running_count\n",
        "                running_loss = 0.\n",
        "                running_count = 0.\n",
        "                if verbose:\n",
        "                    print(f'[Epoch {e+1:2d}/{num_epochs:d} Iter {i+1:5d}/{len(trainloader)}]: train_loss = {train_loss:.4f}')\n",
        "\n",
        "                history.append(train_loss)\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljSQ0NXh-dZD"
      },
      "source": [
        "Define the evaluate function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iBvtq0t3-dZG"
      },
      "outputs": [],
      "source": [
        "def evaluate(net):\n",
        "    # set to evaluation mode\n",
        "    net.eval()\n",
        "\n",
        "    # running_correct\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, targets in testloader:\n",
        "\n",
        "        # transfer to the GPU\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "\n",
        "        # perform prediction (no need to compute gradient)\n",
        "        with torch.no_grad():\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            running_corrects += (targets == predicted).double().sum()\n",
        "\n",
        "    print('Accuracy = {:.2f}%'.format(100*running_corrects/len(testloader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws7qs6tr-dZM"
      },
      "source": [
        "---\n",
        "## 1 Load CIFAR10 dataset\n",
        "\n",
        "Load the dataset with the following transformation pipeline.\n",
        "\n",
        "**Noted:**\n",
        "\n",
        "We are using a sub-sample of CIFAR10 where we use a sub-sample of 1000 training and testing samples.\n",
        "\n",
        "The sample size is **small** and hence is expected to face **overfitting** issue. Using a pretrained model is helpful to alleviate the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1eqihDIp-dZO",
        "outputId": "9c03bde2-f688-4087-cd8c-79f3f5d5cae6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# transform the model\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "trainset = CIFAR10(train=True, download=True, transform=transform, num_samples=1000)\n",
        "testset  = CIFAR10(train=False, download=True, transform=transform, num_samples=1000)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader  = DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNm3qtT0-dZS"
      },
      "source": [
        "---\n",
        "\n",
        "## 2 ResNet50 model\n",
        "\n",
        "In this practical, we will use  a pre-trained [ResNet50](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#resnet50) for the 4 training methods.\n",
        "\n",
        "**Noted:**\n",
        "\n",
        " * The original ResNet50 was designed to classify ImageNet's 1000 image categories\n",
        "\n",
        "* Since we will be using CIFAR10 (10 classes), we need to customize the network by replacing its classifier layer (last fc layer)  later\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.1 Loading the pretrained models\n",
        "\n",
        "`TorchVision` provides two pretrained models for ResNet50 together their reported accurcies on ImageNet-1K with single crops:\n",
        "\n",
        "|**weight**|**Acc@1**|**Acc@5**|**Params**|\n",
        "|:---:|:---:|:---:|:---:|\n",
        "|ResNet50_Weights.IMAGENET1K_V1|76.13|92.862|25.6MB|\n",
        "|ResNet50_Weights.IMAGENET1K_V2|80.858|95.434|25.6MB|\n",
        "\n",
        "where IMAGENET1K_V2 improves upon IMAGENET1K_V1 by using a new [training recipe](https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/)\n",
        "\n",
        "We can specify the pretrained model through:\n",
        "1. predefined constant argument, or\n",
        "2. string argument\n"
      ],
      "metadata": {
        "id": "1y_j55xWu2Ey"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iegSJvm5M8Ty"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JVkKmuqcWfDS",
        "outputId": "1b4684e4-58e2-4a7e-8f0d-1c9b5e129acc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 94.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# load pretrained resnet18 model with predefined constant argument\n",
        "net = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zYI9FrywPL-s"
      },
      "outputs": [],
      "source": [
        "# load pretrained resnet18 model with string argument\n",
        "net = resnet50(weights=\"IMAGENET1K_V2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79wcOsOZObDC"
      },
      "source": [
        "### 2.2 Inferencing with the pretrained model\n",
        "\n",
        "Some pretrained model needs specific preprocessing steps (e.g., resize into a specific resolution / rescale the values, etc.)\n",
        "\n",
        "The preprocessing steps vary depending on how the model was trained. The necessary information for inference transforms are provided on the weight documentation.\n",
        "\n",
        "To simplify inference, `TorchVision` bundle  `transform` utility into `ResNet.Weights` (do not require transform pipelibe)\n",
        "\n",
        "Let's try a simple example of \"tabby cat\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the example image from drive\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1Ury2q1BmuwHO1HufuwmVu3_4zh72UoYT/view?usp=drive_link"
      ],
      "metadata": {
        "id": "4FPljxnbMX2t",
        "outputId": "2c4a412c-b03f-4be9-d7ef-032c87485705",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ury2q1BmuwHO1HufuwmVu3_4zh72UoYT\n",
            "To: /content/gdrive/MyDrive/PDL_2023/P07/Tabby_cat.jpg\n",
            "\r  0% 0.00/17.8k [00:00<?, ?B/s]\r100% 17.8k/17.8k [00:00<00:00, 45.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D5fKx4JcQ0mI"
      },
      "outputs": [],
      "source": [
        "# load the preprocess function for image transformation\n",
        "weight = ResNet50_Weights.IMAGENET1K_V2\n",
        "preprocess = weight.transforms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "g0LHr6uqRten",
        "outputId": "5186fced-a6fc-4c77-94b8-968dd0f53ce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x (before preprocessing) torch.Size([3, 162, 288])\n",
            "Shape of x after preprocessing: torch.Size([3, 224, 224])\n",
            "Shape of x after unsqueezing: torch.Size([1, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# read image\n",
        "from torchvision.io import read_image\n",
        "img = read_image('Tabby_cat.jpg')\n",
        "print('Shape of x (before preprocessing)', img.shape)\n",
        "\n",
        "# preprocess image will return shape (C,H,W)\n",
        "x = preprocess(img)\n",
        "print('Shape of x after preprocessing:', x.shape)\n",
        "\n",
        "# we have to create the batch dimension (1, C, H, W)\n",
        "x = x.unsqueeze(0)\n",
        "\n",
        "print('Shape of x after unsqueezing:', x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRxAm0w7VG44"
      },
      "source": [
        "Now we can perform inference with the pretrained model.\n",
        "\n",
        " The classes of the pretrained model can be found at `weights.meta['categories']`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jLTn5qeFU90g",
        "outputId": "46dc422e-c018-431e-b6b3-3c900d82e7d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label = tabby\n"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "with torch.no_grad():\n",
        "        score = net(x)\n",
        "        predicted = score.argmax(axis=1)[0]\n",
        "\n",
        "print('Predicted label =', weight.meta['categories'][predicted])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kDePxTL7kgV"
      },
      "source": [
        "\n",
        "### 2.3 Customizing ResNet50\n",
        "\n",
        "Now, let's replace the last layer with a new classifier layer so that it is adaptable to  Cifar10's 10 classes.\n",
        "\n",
        "First, let's check the architecture of ResNet50 and how it is implemented in PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cCT1cjPD-dZb",
        "outputId": "470e877a-17ed-45a4-a89c-14ce64a5d99c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check at higher level: displaying only the children of network (named blocks):\n"
      ],
      "metadata": {
        "id": "Iclc6-IM2SCe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CrWZSU_xHLRg",
        "outputId": "7454ae24-89a2-4137-bdcc-50d0eeca86d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1\n",
            "bn1\n",
            "relu\n",
            "maxpool\n",
            "layer1\n",
            "layer2\n",
            "layer3\n",
            "layer4\n",
            "avgpool\n",
            "fc\n"
          ]
        }
      ],
      "source": [
        "# print the children of network\n",
        "for name, _ in net.named_children():\n",
        "       print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JVfe784-dZk"
      },
      "source": [
        "Here are some observations:\n",
        "* `conv1`, `bn1`, `relu` and `maxpool` are the *stem* network\n",
        "* There are 4 *blocks* in the network, namely `layer1`, `layer2`, `layer3` and `layer4`.\n",
        "* Each of the block contains two convolutional layers.\n",
        "* The second last layer (`avgpool`) performs *global average pooling* to average out the spatial dimensions.\n",
        "* The last layer (`fc`) is a linear layer that functions as a classifier. (This is the layer that we want to replace to fit our model)\n",
        "\n",
        "Now, lets customize the network by replacing the `fc` layer with our own classifier layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qJLn-l4C-dZl"
      },
      "outputs": [],
      "source": [
        "def build_network(weights=None):\n",
        "        net = resnet50(weights=weights)\n",
        "        in_c = net.fc.in_features\n",
        "        net.fc = nn.Linear(in_c, 10)\n",
        "        return net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ0QEzwX-dZr"
      },
      "source": [
        "Let's visualize the customized network again.\n",
        "\n",
        "You should find  the last layer of the network (`fc`) now has 10 instead of 1000 neurons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "H83zW0QF-dZs",
        "scrolled": false,
        "outputId": "539f5b22-fdcc-43dc-e51e-9bf48aba9078",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(build_network())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j76AmVMR-dZ0"
      },
      "source": [
        "---\n",
        "## Model 1: Training from scratch\n",
        "\n",
        "To train the ResNet50 from scratch, the weights are initialized randomly as standard training.\n",
        "\n",
        "Let's build the network **without** loading the pretrained model. To do this, we shall set `weights=None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "s1bzb0AF-dZ1"
      },
      "outputs": [],
      "source": [
        "# Load the an empty model (without pretrained weights)\n",
        "net1 = build_network(weights=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke4oRDBD-dZ4"
      },
      "source": [
        "Train the model and save the training loss history into `history1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ozXEDbIU-dZ6",
        "outputId": "956ff260-bf1f-485f-f818-365b7f840845",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  1/30 Iter    32/32]: train_loss = 4.0904\n",
            "[Epoch  2/30 Iter    32/32]: train_loss = 2.8636\n",
            "[Epoch  3/30 Iter    32/32]: train_loss = 2.5567\n",
            "[Epoch  4/30 Iter    32/32]: train_loss = 2.3508\n",
            "[Epoch  5/30 Iter    32/32]: train_loss = 2.2909\n",
            "[Epoch  6/30 Iter    32/32]: train_loss = 2.0776\n",
            "[Epoch  7/30 Iter    32/32]: train_loss = 2.0285\n",
            "[Epoch  8/30 Iter    32/32]: train_loss = 2.0023\n",
            "[Epoch  9/30 Iter    32/32]: train_loss = 1.9648\n",
            "[Epoch 10/30 Iter    32/32]: train_loss = 1.8828\n",
            "[Epoch 11/30 Iter    32/32]: train_loss = 1.8560\n",
            "[Epoch 12/30 Iter    32/32]: train_loss = 1.8321\n",
            "[Epoch 13/30 Iter    32/32]: train_loss = 1.8239\n",
            "[Epoch 14/30 Iter    32/32]: train_loss = 1.7725\n",
            "[Epoch 15/30 Iter    32/32]: train_loss = 1.9025\n",
            "[Epoch 16/30 Iter    32/32]: train_loss = 1.7298\n",
            "[Epoch 17/30 Iter    32/32]: train_loss = 1.7412\n",
            "[Epoch 18/30 Iter    32/32]: train_loss = 1.7106\n",
            "[Epoch 19/30 Iter    32/32]: train_loss = 1.6115\n",
            "[Epoch 20/30 Iter    32/32]: train_loss = 1.6704\n",
            "[Epoch 21/30 Iter    32/32]: train_loss = 1.6019\n",
            "[Epoch 22/30 Iter    32/32]: train_loss = 1.5166\n",
            "[Epoch 23/30 Iter    32/32]: train_loss = 1.5607\n",
            "[Epoch 24/30 Iter    32/32]: train_loss = 1.5409\n",
            "[Epoch 25/30 Iter    32/32]: train_loss = 1.5374\n",
            "[Epoch 26/30 Iter    32/32]: train_loss = 1.4748\n",
            "[Epoch 27/30 Iter    32/32]: train_loss = 1.4746\n",
            "[Epoch 28/30 Iter    32/32]: train_loss = 1.4240\n",
            "[Epoch 29/30 Iter    32/32]: train_loss = 1.3872\n",
            "[Epoch 30/30 Iter    32/32]: train_loss = 1.3952\n"
          ]
        }
      ],
      "source": [
        "history1 = train(net1, num_epochs=30, lr=0.01, momentum=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYgMvo78-daA"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BZUzQ3LO-daB",
        "outputId": "feb9d3b3-5a8b-426d-f23c-081de5c4c2bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 33.20%\n"
          ]
        }
      ],
      "source": [
        "evaluate(net1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoCFbpik-daG"
      },
      "source": [
        "---\n",
        "## Model 2: Finetuning the entire model\n",
        "\n",
        "To finetune the ResNet50,we will initialize the network with the pretrained weights.\n",
        "\n",
        "Let's load ResNet50 with the pretrained weights and use it to initialize the network.  To do this, we set `weights='IMAGENET1K_V2'`.\n",
        "\n",
        "**Noted:**\n",
        "\n",
        "The training will update ALL the parameters in every layers of the network.\n",
        "\n",
        "**For Windows system:** (local GPU)\n",
        "\n",
        "The pretrained model will be saved to the following directory: `C:\\Users\\<user name>\\.cache\\torch\\checkpoints`. A PyTorch model has an extension of `.pt` or `.pth`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "L4OgAOih-daH"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained model\n",
        "net2 = build_network(weights='IMAGENET1K_V2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fZn_3_X-dac"
      },
      "source": [
        "By default, all the layers are set to `requires_grad=True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Z57XPXtt-dad",
        "outputId": "f1d3a53f-7e98-4081-d6f3-db230dae4664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight : True\n",
            "bn1.weight : True\n",
            "bn1.bias : True\n",
            "layer1.0.conv1.weight : True\n",
            "layer1.0.bn1.weight : True\n",
            "layer1.0.bn1.bias : True\n",
            "layer1.0.conv2.weight : True\n",
            "layer1.0.bn2.weight : True\n",
            "layer1.0.bn2.bias : True\n",
            "layer1.0.conv3.weight : True\n",
            "layer1.0.bn3.weight : True\n",
            "layer1.0.bn3.bias : True\n",
            "layer1.0.downsample.0.weight : True\n",
            "layer1.0.downsample.1.weight : True\n",
            "layer1.0.downsample.1.bias : True\n",
            "layer1.1.conv1.weight : True\n",
            "layer1.1.bn1.weight : True\n",
            "layer1.1.bn1.bias : True\n",
            "layer1.1.conv2.weight : True\n",
            "layer1.1.bn2.weight : True\n",
            "layer1.1.bn2.bias : True\n",
            "layer1.1.conv3.weight : True\n",
            "layer1.1.bn3.weight : True\n",
            "layer1.1.bn3.bias : True\n",
            "layer1.2.conv1.weight : True\n",
            "layer1.2.bn1.weight : True\n",
            "layer1.2.bn1.bias : True\n",
            "layer1.2.conv2.weight : True\n",
            "layer1.2.bn2.weight : True\n",
            "layer1.2.bn2.bias : True\n",
            "layer1.2.conv3.weight : True\n",
            "layer1.2.bn3.weight : True\n",
            "layer1.2.bn3.bias : True\n",
            "layer2.0.conv1.weight : True\n",
            "layer2.0.bn1.weight : True\n",
            "layer2.0.bn1.bias : True\n",
            "layer2.0.conv2.weight : True\n",
            "layer2.0.bn2.weight : True\n",
            "layer2.0.bn2.bias : True\n",
            "layer2.0.conv3.weight : True\n",
            "layer2.0.bn3.weight : True\n",
            "layer2.0.bn3.bias : True\n",
            "layer2.0.downsample.0.weight : True\n",
            "layer2.0.downsample.1.weight : True\n",
            "layer2.0.downsample.1.bias : True\n",
            "layer2.1.conv1.weight : True\n",
            "layer2.1.bn1.weight : True\n",
            "layer2.1.bn1.bias : True\n",
            "layer2.1.conv2.weight : True\n",
            "layer2.1.bn2.weight : True\n",
            "layer2.1.bn2.bias : True\n",
            "layer2.1.conv3.weight : True\n",
            "layer2.1.bn3.weight : True\n",
            "layer2.1.bn3.bias : True\n",
            "layer2.2.conv1.weight : True\n",
            "layer2.2.bn1.weight : True\n",
            "layer2.2.bn1.bias : True\n",
            "layer2.2.conv2.weight : True\n",
            "layer2.2.bn2.weight : True\n",
            "layer2.2.bn2.bias : True\n",
            "layer2.2.conv3.weight : True\n",
            "layer2.2.bn3.weight : True\n",
            "layer2.2.bn3.bias : True\n",
            "layer2.3.conv1.weight : True\n",
            "layer2.3.bn1.weight : True\n",
            "layer2.3.bn1.bias : True\n",
            "layer2.3.conv2.weight : True\n",
            "layer2.3.bn2.weight : True\n",
            "layer2.3.bn2.bias : True\n",
            "layer2.3.conv3.weight : True\n",
            "layer2.3.bn3.weight : True\n",
            "layer2.3.bn3.bias : True\n",
            "layer3.0.conv1.weight : True\n",
            "layer3.0.bn1.weight : True\n",
            "layer3.0.bn1.bias : True\n",
            "layer3.0.conv2.weight : True\n",
            "layer3.0.bn2.weight : True\n",
            "layer3.0.bn2.bias : True\n",
            "layer3.0.conv3.weight : True\n",
            "layer3.0.bn3.weight : True\n",
            "layer3.0.bn3.bias : True\n",
            "layer3.0.downsample.0.weight : True\n",
            "layer3.0.downsample.1.weight : True\n",
            "layer3.0.downsample.1.bias : True\n",
            "layer3.1.conv1.weight : True\n",
            "layer3.1.bn1.weight : True\n",
            "layer3.1.bn1.bias : True\n",
            "layer3.1.conv2.weight : True\n",
            "layer3.1.bn2.weight : True\n",
            "layer3.1.bn2.bias : True\n",
            "layer3.1.conv3.weight : True\n",
            "layer3.1.bn3.weight : True\n",
            "layer3.1.bn3.bias : True\n",
            "layer3.2.conv1.weight : True\n",
            "layer3.2.bn1.weight : True\n",
            "layer3.2.bn1.bias : True\n",
            "layer3.2.conv2.weight : True\n",
            "layer3.2.bn2.weight : True\n",
            "layer3.2.bn2.bias : True\n",
            "layer3.2.conv3.weight : True\n",
            "layer3.2.bn3.weight : True\n",
            "layer3.2.bn3.bias : True\n",
            "layer3.3.conv1.weight : True\n",
            "layer3.3.bn1.weight : True\n",
            "layer3.3.bn1.bias : True\n",
            "layer3.3.conv2.weight : True\n",
            "layer3.3.bn2.weight : True\n",
            "layer3.3.bn2.bias : True\n",
            "layer3.3.conv3.weight : True\n",
            "layer3.3.bn3.weight : True\n",
            "layer3.3.bn3.bias : True\n",
            "layer3.4.conv1.weight : True\n",
            "layer3.4.bn1.weight : True\n",
            "layer3.4.bn1.bias : True\n",
            "layer3.4.conv2.weight : True\n",
            "layer3.4.bn2.weight : True\n",
            "layer3.4.bn2.bias : True\n",
            "layer3.4.conv3.weight : True\n",
            "layer3.4.bn3.weight : True\n",
            "layer3.4.bn3.bias : True\n",
            "layer3.5.conv1.weight : True\n",
            "layer3.5.bn1.weight : True\n",
            "layer3.5.bn1.bias : True\n",
            "layer3.5.conv2.weight : True\n",
            "layer3.5.bn2.weight : True\n",
            "layer3.5.bn2.bias : True\n",
            "layer3.5.conv3.weight : True\n",
            "layer3.5.bn3.weight : True\n",
            "layer3.5.bn3.bias : True\n",
            "layer4.0.conv1.weight : True\n",
            "layer4.0.bn1.weight : True\n",
            "layer4.0.bn1.bias : True\n",
            "layer4.0.conv2.weight : True\n",
            "layer4.0.bn2.weight : True\n",
            "layer4.0.bn2.bias : True\n",
            "layer4.0.conv3.weight : True\n",
            "layer4.0.bn3.weight : True\n",
            "layer4.0.bn3.bias : True\n",
            "layer4.0.downsample.0.weight : True\n",
            "layer4.0.downsample.1.weight : True\n",
            "layer4.0.downsample.1.bias : True\n",
            "layer4.1.conv1.weight : True\n",
            "layer4.1.bn1.weight : True\n",
            "layer4.1.bn1.bias : True\n",
            "layer4.1.conv2.weight : True\n",
            "layer4.1.bn2.weight : True\n",
            "layer4.1.bn2.bias : True\n",
            "layer4.1.conv3.weight : True\n",
            "layer4.1.bn3.weight : True\n",
            "layer4.1.bn3.bias : True\n",
            "layer4.2.conv1.weight : True\n",
            "layer4.2.bn1.weight : True\n",
            "layer4.2.bn1.bias : True\n",
            "layer4.2.conv2.weight : True\n",
            "layer4.2.bn2.weight : True\n",
            "layer4.2.bn2.bias : True\n",
            "layer4.2.conv3.weight : True\n",
            "layer4.2.bn3.weight : True\n",
            "layer4.2.bn3.bias : True\n",
            "fc.weight : True\n",
            "fc.bias : True\n"
          ]
        }
      ],
      "source": [
        "# display the requires_grad for all layers\n",
        "for name, param in net2.named_parameters():\n",
        "       print(name, ':', param.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WCRuqTd-daM"
      },
      "source": [
        "Train the model and save into `history2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MxNWP06d-daN",
        "outputId": "99d1a262-0fd0-4831-e428-1f19da84fff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  1/30 Iter    32/32]: train_loss = 2.0154\n",
            "[Epoch  2/30 Iter    32/32]: train_loss = 1.0903\n",
            "[Epoch  3/30 Iter    32/32]: train_loss = 0.6149\n",
            "[Epoch  4/30 Iter    32/32]: train_loss = 0.4009\n",
            "[Epoch  5/30 Iter    32/32]: train_loss = 0.2087\n",
            "[Epoch  6/30 Iter    32/32]: train_loss = 0.1762\n",
            "[Epoch  7/30 Iter    32/32]: train_loss = 0.1160\n",
            "[Epoch  8/30 Iter    32/32]: train_loss = 0.1356\n",
            "[Epoch  9/30 Iter    32/32]: train_loss = 0.1048\n",
            "[Epoch 10/30 Iter    32/32]: train_loss = 0.0570\n",
            "[Epoch 11/30 Iter    32/32]: train_loss = 0.0592\n",
            "[Epoch 12/30 Iter    32/32]: train_loss = 0.0606\n",
            "[Epoch 13/30 Iter    32/32]: train_loss = 0.0585\n",
            "[Epoch 14/30 Iter    32/32]: train_loss = 0.0522\n",
            "[Epoch 15/30 Iter    32/32]: train_loss = 0.0351\n",
            "[Epoch 16/30 Iter    32/32]: train_loss = 0.0374\n",
            "[Epoch 17/30 Iter    32/32]: train_loss = 0.0512\n",
            "[Epoch 18/30 Iter    32/32]: train_loss = 0.0302\n",
            "[Epoch 19/30 Iter    32/32]: train_loss = 0.0278\n",
            "[Epoch 20/30 Iter    32/32]: train_loss = 0.0224\n",
            "[Epoch 21/30 Iter    32/32]: train_loss = 0.0393\n",
            "[Epoch 22/30 Iter    32/32]: train_loss = 0.0138\n",
            "[Epoch 23/30 Iter    32/32]: train_loss = 0.0219\n",
            "[Epoch 24/30 Iter    32/32]: train_loss = 0.0227\n",
            "[Epoch 25/30 Iter    32/32]: train_loss = 0.0127\n",
            "[Epoch 26/30 Iter    32/32]: train_loss = 0.0473\n",
            "[Epoch 27/30 Iter    32/32]: train_loss = 0.1008\n",
            "[Epoch 28/30 Iter    32/32]: train_loss = 0.0488\n",
            "[Epoch 29/30 Iter    32/32]: train_loss = 0.0353\n",
            "[Epoch 30/30 Iter    32/32]: train_loss = 0.0395\n"
          ]
        }
      ],
      "source": [
        "history2 = train(net2, num_epochs=30, lr=0.01, momentum=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZN6nYHR-daQ"
      },
      "source": [
        "Evaluate the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qjkHZEfx-daR",
        "outputId": "e04b2278-7429-4fc7-9da6-17c0fa2868e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 83.00%\n"
          ]
        }
      ],
      "source": [
        "evaluate(net2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNU2oW6n-daV"
      },
      "source": [
        "---\n",
        "## Model 3: Finetuning the fc layers (fixed feature extractor)\n",
        "\n",
        "When the dataset is too small, fine-tuning the model may still incur overfitting.\n",
        "\n",
        "In this case, you may want to try to use the pretrained network as a fixed feature extractor where we train only the  classifier (fc layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4E9-Smri-daX"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained model\n",
        "net3 = build_network(weights='IMAGENET1K_V2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGZpQHKM-dag"
      },
      "source": [
        "To freeze the feature extractor, we have to set `requires_grad=False` for all parameters in  `resnet.parameters()` except for the new  `fc` layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5-9dSPUW-dag"
      },
      "outputs": [],
      "source": [
        "# set requires grad to FALSE for all parameters except the fc layer\n",
        "parameters = list(net3.parameters())\n",
        "for param in parameters[:-2]:\n",
        "       param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rdA2balW-daj",
        "outputId": "80f6f550-794f-4780-be5a-e98b7f3af59a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight : False\n",
            "bn1.weight : False\n",
            "bn1.bias : False\n",
            "layer1.0.conv1.weight : False\n",
            "layer1.0.bn1.weight : False\n",
            "layer1.0.bn1.bias : False\n",
            "layer1.0.conv2.weight : False\n",
            "layer1.0.bn2.weight : False\n",
            "layer1.0.bn2.bias : False\n",
            "layer1.0.conv3.weight : False\n",
            "layer1.0.bn3.weight : False\n",
            "layer1.0.bn3.bias : False\n",
            "layer1.0.downsample.0.weight : False\n",
            "layer1.0.downsample.1.weight : False\n",
            "layer1.0.downsample.1.bias : False\n",
            "layer1.1.conv1.weight : False\n",
            "layer1.1.bn1.weight : False\n",
            "layer1.1.bn1.bias : False\n",
            "layer1.1.conv2.weight : False\n",
            "layer1.1.bn2.weight : False\n",
            "layer1.1.bn2.bias : False\n",
            "layer1.1.conv3.weight : False\n",
            "layer1.1.bn3.weight : False\n",
            "layer1.1.bn3.bias : False\n",
            "layer1.2.conv1.weight : False\n",
            "layer1.2.bn1.weight : False\n",
            "layer1.2.bn1.bias : False\n",
            "layer1.2.conv2.weight : False\n",
            "layer1.2.bn2.weight : False\n",
            "layer1.2.bn2.bias : False\n",
            "layer1.2.conv3.weight : False\n",
            "layer1.2.bn3.weight : False\n",
            "layer1.2.bn3.bias : False\n",
            "layer2.0.conv1.weight : False\n",
            "layer2.0.bn1.weight : False\n",
            "layer2.0.bn1.bias : False\n",
            "layer2.0.conv2.weight : False\n",
            "layer2.0.bn2.weight : False\n",
            "layer2.0.bn2.bias : False\n",
            "layer2.0.conv3.weight : False\n",
            "layer2.0.bn3.weight : False\n",
            "layer2.0.bn3.bias : False\n",
            "layer2.0.downsample.0.weight : False\n",
            "layer2.0.downsample.1.weight : False\n",
            "layer2.0.downsample.1.bias : False\n",
            "layer2.1.conv1.weight : False\n",
            "layer2.1.bn1.weight : False\n",
            "layer2.1.bn1.bias : False\n",
            "layer2.1.conv2.weight : False\n",
            "layer2.1.bn2.weight : False\n",
            "layer2.1.bn2.bias : False\n",
            "layer2.1.conv3.weight : False\n",
            "layer2.1.bn3.weight : False\n",
            "layer2.1.bn3.bias : False\n",
            "layer2.2.conv1.weight : False\n",
            "layer2.2.bn1.weight : False\n",
            "layer2.2.bn1.bias : False\n",
            "layer2.2.conv2.weight : False\n",
            "layer2.2.bn2.weight : False\n",
            "layer2.2.bn2.bias : False\n",
            "layer2.2.conv3.weight : False\n",
            "layer2.2.bn3.weight : False\n",
            "layer2.2.bn3.bias : False\n",
            "layer2.3.conv1.weight : False\n",
            "layer2.3.bn1.weight : False\n",
            "layer2.3.bn1.bias : False\n",
            "layer2.3.conv2.weight : False\n",
            "layer2.3.bn2.weight : False\n",
            "layer2.3.bn2.bias : False\n",
            "layer2.3.conv3.weight : False\n",
            "layer2.3.bn3.weight : False\n",
            "layer2.3.bn3.bias : False\n",
            "layer3.0.conv1.weight : False\n",
            "layer3.0.bn1.weight : False\n",
            "layer3.0.bn1.bias : False\n",
            "layer3.0.conv2.weight : False\n",
            "layer3.0.bn2.weight : False\n",
            "layer3.0.bn2.bias : False\n",
            "layer3.0.conv3.weight : False\n",
            "layer3.0.bn3.weight : False\n",
            "layer3.0.bn3.bias : False\n",
            "layer3.0.downsample.0.weight : False\n",
            "layer3.0.downsample.1.weight : False\n",
            "layer3.0.downsample.1.bias : False\n",
            "layer3.1.conv1.weight : False\n",
            "layer3.1.bn1.weight : False\n",
            "layer3.1.bn1.bias : False\n",
            "layer3.1.conv2.weight : False\n",
            "layer3.1.bn2.weight : False\n",
            "layer3.1.bn2.bias : False\n",
            "layer3.1.conv3.weight : False\n",
            "layer3.1.bn3.weight : False\n",
            "layer3.1.bn3.bias : False\n",
            "layer3.2.conv1.weight : False\n",
            "layer3.2.bn1.weight : False\n",
            "layer3.2.bn1.bias : False\n",
            "layer3.2.conv2.weight : False\n",
            "layer3.2.bn2.weight : False\n",
            "layer3.2.bn2.bias : False\n",
            "layer3.2.conv3.weight : False\n",
            "layer3.2.bn3.weight : False\n",
            "layer3.2.bn3.bias : False\n",
            "layer3.3.conv1.weight : False\n",
            "layer3.3.bn1.weight : False\n",
            "layer3.3.bn1.bias : False\n",
            "layer3.3.conv2.weight : False\n",
            "layer3.3.bn2.weight : False\n",
            "layer3.3.bn2.bias : False\n",
            "layer3.3.conv3.weight : False\n",
            "layer3.3.bn3.weight : False\n",
            "layer3.3.bn3.bias : False\n",
            "layer3.4.conv1.weight : False\n",
            "layer3.4.bn1.weight : False\n",
            "layer3.4.bn1.bias : False\n",
            "layer3.4.conv2.weight : False\n",
            "layer3.4.bn2.weight : False\n",
            "layer3.4.bn2.bias : False\n",
            "layer3.4.conv3.weight : False\n",
            "layer3.4.bn3.weight : False\n",
            "layer3.4.bn3.bias : False\n",
            "layer3.5.conv1.weight : False\n",
            "layer3.5.bn1.weight : False\n",
            "layer3.5.bn1.bias : False\n",
            "layer3.5.conv2.weight : False\n",
            "layer3.5.bn2.weight : False\n",
            "layer3.5.bn2.bias : False\n",
            "layer3.5.conv3.weight : False\n",
            "layer3.5.bn3.weight : False\n",
            "layer3.5.bn3.bias : False\n",
            "layer4.0.conv1.weight : False\n",
            "layer4.0.bn1.weight : False\n",
            "layer4.0.bn1.bias : False\n",
            "layer4.0.conv2.weight : False\n",
            "layer4.0.bn2.weight : False\n",
            "layer4.0.bn2.bias : False\n",
            "layer4.0.conv3.weight : False\n",
            "layer4.0.bn3.weight : False\n",
            "layer4.0.bn3.bias : False\n",
            "layer4.0.downsample.0.weight : False\n",
            "layer4.0.downsample.1.weight : False\n",
            "layer4.0.downsample.1.bias : False\n",
            "layer4.1.conv1.weight : False\n",
            "layer4.1.bn1.weight : False\n",
            "layer4.1.bn1.bias : False\n",
            "layer4.1.conv2.weight : False\n",
            "layer4.1.bn2.weight : False\n",
            "layer4.1.bn2.bias : False\n",
            "layer4.1.conv3.weight : False\n",
            "layer4.1.bn3.weight : False\n",
            "layer4.1.bn3.bias : False\n",
            "layer4.2.conv1.weight : False\n",
            "layer4.2.bn1.weight : False\n",
            "layer4.2.bn1.bias : False\n",
            "layer4.2.conv2.weight : False\n",
            "layer4.2.bn2.weight : False\n",
            "layer4.2.bn2.bias : False\n",
            "layer4.2.conv3.weight : False\n",
            "layer4.2.bn3.weight : False\n",
            "layer4.2.bn3.bias : False\n",
            "fc.weight : True\n",
            "fc.bias : True\n"
          ]
        }
      ],
      "source": [
        "# display the requires_grad for all layers to confirm that the gradients have been set correctly\n",
        "for name, param in net3.named_parameters():\n",
        "        print(name, ':', param.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5tAEgqj-dam"
      },
      "source": [
        "Train the model and save into `history3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "upS5DzLI-dao",
        "outputId": "b854c8d4-f261-4376-80fc-24e8978a1d8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  1/30 Iter    32/32]: train_loss = 2.0597\n",
            "[Epoch  2/30 Iter    32/32]: train_loss = 1.5939\n",
            "[Epoch  3/30 Iter    32/32]: train_loss = 1.3564\n",
            "[Epoch  4/30 Iter    32/32]: train_loss = 1.2485\n",
            "[Epoch  5/30 Iter    32/32]: train_loss = 1.1775\n",
            "[Epoch  6/30 Iter    32/32]: train_loss = 1.0834\n",
            "[Epoch  7/30 Iter    32/32]: train_loss = 1.0292\n",
            "[Epoch  8/30 Iter    32/32]: train_loss = 0.9773\n",
            "[Epoch  9/30 Iter    32/32]: train_loss = 0.9618\n",
            "[Epoch 10/30 Iter    32/32]: train_loss = 0.9113\n",
            "[Epoch 11/30 Iter    32/32]: train_loss = 0.8969\n",
            "[Epoch 12/30 Iter    32/32]: train_loss = 0.8716\n",
            "[Epoch 13/30 Iter    32/32]: train_loss = 0.8521\n",
            "[Epoch 14/30 Iter    32/32]: train_loss = 0.8350\n",
            "[Epoch 15/30 Iter    32/32]: train_loss = 0.8326\n",
            "[Epoch 16/30 Iter    32/32]: train_loss = 0.8062\n",
            "[Epoch 17/30 Iter    32/32]: train_loss = 0.7812\n",
            "[Epoch 18/30 Iter    32/32]: train_loss = 0.7922\n",
            "[Epoch 19/30 Iter    32/32]: train_loss = 0.7602\n",
            "[Epoch 20/30 Iter    32/32]: train_loss = 0.7527\n",
            "[Epoch 21/30 Iter    32/32]: train_loss = 0.7454\n",
            "[Epoch 22/30 Iter    32/32]: train_loss = 0.7271\n",
            "[Epoch 23/30 Iter    32/32]: train_loss = 0.7277\n",
            "[Epoch 24/30 Iter    32/32]: train_loss = 0.7016\n",
            "[Epoch 25/30 Iter    32/32]: train_loss = 0.6824\n",
            "[Epoch 26/30 Iter    32/32]: train_loss = 0.6938\n",
            "[Epoch 27/30 Iter    32/32]: train_loss = 0.6736\n",
            "[Epoch 28/30 Iter    32/32]: train_loss = 0.6469\n",
            "[Epoch 29/30 Iter    32/32]: train_loss = 0.6522\n",
            "[Epoch 30/30 Iter    32/32]: train_loss = 0.6761\n"
          ]
        }
      ],
      "source": [
        "history3 = train(net3, num_epochs=30, lr=0.01, momentum=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHbWS81I-dav"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wEd3pB8J-day",
        "outputId": "d948d278-30f8-4355-c87e-70a9becc4d24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 70.00%\n"
          ]
        }
      ],
      "source": [
        "evaluate(net3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjwhSdAa-da1"
      },
      "source": [
        "---\n",
        "## Model 4: Finetune the top (last few) layers\n",
        "\n",
        "Sometime, you may want to finetune the feature extractor for higher-level features.\n",
        "\n",
        "To do this, we can tune the top few layers of the network (layers in the block `layer 4` and `fc` layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "K9pDdnsf-da2"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained model\n",
        "net4 = build_network(weights='IMAGENET1K_V2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nejPZBc1-da5"
      },
      "source": [
        "Then, we freeze all tha layers except for `layer4` and `fc` layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VfolcT6O-da6"
      },
      "outputs": [],
      "source": [
        "for name, param in net4.named_parameters():\n",
        "       if not any(name.startswith(ext) for ext in ['layer4', 'fc']):\n",
        "           param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-CNGLTmQ-dbB",
        "outputId": "3376305b-e4a2-499c-be25-d71168157f29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight : False\n",
            "bn1.weight : False\n",
            "bn1.bias : False\n",
            "layer1.0.conv1.weight : False\n",
            "layer1.0.bn1.weight : False\n",
            "layer1.0.bn1.bias : False\n",
            "layer1.0.conv2.weight : False\n",
            "layer1.0.bn2.weight : False\n",
            "layer1.0.bn2.bias : False\n",
            "layer1.0.conv3.weight : False\n",
            "layer1.0.bn3.weight : False\n",
            "layer1.0.bn3.bias : False\n",
            "layer1.0.downsample.0.weight : False\n",
            "layer1.0.downsample.1.weight : False\n",
            "layer1.0.downsample.1.bias : False\n",
            "layer1.1.conv1.weight : False\n",
            "layer1.1.bn1.weight : False\n",
            "layer1.1.bn1.bias : False\n",
            "layer1.1.conv2.weight : False\n",
            "layer1.1.bn2.weight : False\n",
            "layer1.1.bn2.bias : False\n",
            "layer1.1.conv3.weight : False\n",
            "layer1.1.bn3.weight : False\n",
            "layer1.1.bn3.bias : False\n",
            "layer1.2.conv1.weight : False\n",
            "layer1.2.bn1.weight : False\n",
            "layer1.2.bn1.bias : False\n",
            "layer1.2.conv2.weight : False\n",
            "layer1.2.bn2.weight : False\n",
            "layer1.2.bn2.bias : False\n",
            "layer1.2.conv3.weight : False\n",
            "layer1.2.bn3.weight : False\n",
            "layer1.2.bn3.bias : False\n",
            "layer2.0.conv1.weight : False\n",
            "layer2.0.bn1.weight : False\n",
            "layer2.0.bn1.bias : False\n",
            "layer2.0.conv2.weight : False\n",
            "layer2.0.bn2.weight : False\n",
            "layer2.0.bn2.bias : False\n",
            "layer2.0.conv3.weight : False\n",
            "layer2.0.bn3.weight : False\n",
            "layer2.0.bn3.bias : False\n",
            "layer2.0.downsample.0.weight : False\n",
            "layer2.0.downsample.1.weight : False\n",
            "layer2.0.downsample.1.bias : False\n",
            "layer2.1.conv1.weight : False\n",
            "layer2.1.bn1.weight : False\n",
            "layer2.1.bn1.bias : False\n",
            "layer2.1.conv2.weight : False\n",
            "layer2.1.bn2.weight : False\n",
            "layer2.1.bn2.bias : False\n",
            "layer2.1.conv3.weight : False\n",
            "layer2.1.bn3.weight : False\n",
            "layer2.1.bn3.bias : False\n",
            "layer2.2.conv1.weight : False\n",
            "layer2.2.bn1.weight : False\n",
            "layer2.2.bn1.bias : False\n",
            "layer2.2.conv2.weight : False\n",
            "layer2.2.bn2.weight : False\n",
            "layer2.2.bn2.bias : False\n",
            "layer2.2.conv3.weight : False\n",
            "layer2.2.bn3.weight : False\n",
            "layer2.2.bn3.bias : False\n",
            "layer2.3.conv1.weight : False\n",
            "layer2.3.bn1.weight : False\n",
            "layer2.3.bn1.bias : False\n",
            "layer2.3.conv2.weight : False\n",
            "layer2.3.bn2.weight : False\n",
            "layer2.3.bn2.bias : False\n",
            "layer2.3.conv3.weight : False\n",
            "layer2.3.bn3.weight : False\n",
            "layer2.3.bn3.bias : False\n",
            "layer3.0.conv1.weight : False\n",
            "layer3.0.bn1.weight : False\n",
            "layer3.0.bn1.bias : False\n",
            "layer3.0.conv2.weight : False\n",
            "layer3.0.bn2.weight : False\n",
            "layer3.0.bn2.bias : False\n",
            "layer3.0.conv3.weight : False\n",
            "layer3.0.bn3.weight : False\n",
            "layer3.0.bn3.bias : False\n",
            "layer3.0.downsample.0.weight : False\n",
            "layer3.0.downsample.1.weight : False\n",
            "layer3.0.downsample.1.bias : False\n",
            "layer3.1.conv1.weight : False\n",
            "layer3.1.bn1.weight : False\n",
            "layer3.1.bn1.bias : False\n",
            "layer3.1.conv2.weight : False\n",
            "layer3.1.bn2.weight : False\n",
            "layer3.1.bn2.bias : False\n",
            "layer3.1.conv3.weight : False\n",
            "layer3.1.bn3.weight : False\n",
            "layer3.1.bn3.bias : False\n",
            "layer3.2.conv1.weight : False\n",
            "layer3.2.bn1.weight : False\n",
            "layer3.2.bn1.bias : False\n",
            "layer3.2.conv2.weight : False\n",
            "layer3.2.bn2.weight : False\n",
            "layer3.2.bn2.bias : False\n",
            "layer3.2.conv3.weight : False\n",
            "layer3.2.bn3.weight : False\n",
            "layer3.2.bn3.bias : False\n",
            "layer3.3.conv1.weight : False\n",
            "layer3.3.bn1.weight : False\n",
            "layer3.3.bn1.bias : False\n",
            "layer3.3.conv2.weight : False\n",
            "layer3.3.bn2.weight : False\n",
            "layer3.3.bn2.bias : False\n",
            "layer3.3.conv3.weight : False\n",
            "layer3.3.bn3.weight : False\n",
            "layer3.3.bn3.bias : False\n",
            "layer3.4.conv1.weight : False\n",
            "layer3.4.bn1.weight : False\n",
            "layer3.4.bn1.bias : False\n",
            "layer3.4.conv2.weight : False\n",
            "layer3.4.bn2.weight : False\n",
            "layer3.4.bn2.bias : False\n",
            "layer3.4.conv3.weight : False\n",
            "layer3.4.bn3.weight : False\n",
            "layer3.4.bn3.bias : False\n",
            "layer3.5.conv1.weight : False\n",
            "layer3.5.bn1.weight : False\n",
            "layer3.5.bn1.bias : False\n",
            "layer3.5.conv2.weight : False\n",
            "layer3.5.bn2.weight : False\n",
            "layer3.5.bn2.bias : False\n",
            "layer3.5.conv3.weight : False\n",
            "layer3.5.bn3.weight : False\n",
            "layer3.5.bn3.bias : False\n",
            "layer4.0.conv1.weight : True\n",
            "layer4.0.bn1.weight : True\n",
            "layer4.0.bn1.bias : True\n",
            "layer4.0.conv2.weight : True\n",
            "layer4.0.bn2.weight : True\n",
            "layer4.0.bn2.bias : True\n",
            "layer4.0.conv3.weight : True\n",
            "layer4.0.bn3.weight : True\n",
            "layer4.0.bn3.bias : True\n",
            "layer4.0.downsample.0.weight : True\n",
            "layer4.0.downsample.1.weight : True\n",
            "layer4.0.downsample.1.bias : True\n",
            "layer4.1.conv1.weight : True\n",
            "layer4.1.bn1.weight : True\n",
            "layer4.1.bn1.bias : True\n",
            "layer4.1.conv2.weight : True\n",
            "layer4.1.bn2.weight : True\n",
            "layer4.1.bn2.bias : True\n",
            "layer4.1.conv3.weight : True\n",
            "layer4.1.bn3.weight : True\n",
            "layer4.1.bn3.bias : True\n",
            "layer4.2.conv1.weight : True\n",
            "layer4.2.bn1.weight : True\n",
            "layer4.2.bn1.bias : True\n",
            "layer4.2.conv2.weight : True\n",
            "layer4.2.bn2.weight : True\n",
            "layer4.2.bn2.bias : True\n",
            "layer4.2.conv3.weight : True\n",
            "layer4.2.bn3.weight : True\n",
            "layer4.2.bn3.bias : True\n",
            "fc.weight : True\n",
            "fc.bias : True\n"
          ]
        }
      ],
      "source": [
        "for name, param in net4.named_parameters():\n",
        "       print(name, ':', param.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyR4vKxz-dbH"
      },
      "source": [
        "Train the model and save into `history4`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DGIpDEO6-dbI",
        "outputId": "2336a282-4017-4d06-808d-3095a6b2f318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  1/30 Iter    32/32]: train_loss = 1.9984\n",
            "[Epoch  2/30 Iter    32/32]: train_loss = 1.2703\n",
            "[Epoch  3/30 Iter    32/32]: train_loss = 0.9334\n",
            "[Epoch  4/30 Iter    32/32]: train_loss = 0.7327\n",
            "[Epoch  5/30 Iter    32/32]: train_loss = 0.6493\n",
            "[Epoch  6/30 Iter    32/32]: train_loss = 0.5215\n",
            "[Epoch  7/30 Iter    32/32]: train_loss = 0.4646\n",
            "[Epoch  8/30 Iter    32/32]: train_loss = 0.3755\n",
            "[Epoch  9/30 Iter    32/32]: train_loss = 0.3027\n",
            "[Epoch 10/30 Iter    32/32]: train_loss = 0.2641\n",
            "[Epoch 11/30 Iter    32/32]: train_loss = 0.2150\n",
            "[Epoch 12/30 Iter    32/32]: train_loss = 0.1874\n",
            "[Epoch 13/30 Iter    32/32]: train_loss = 0.1496\n",
            "[Epoch 14/30 Iter    32/32]: train_loss = 0.1750\n",
            "[Epoch 15/30 Iter    32/32]: train_loss = 0.1755\n",
            "[Epoch 16/30 Iter    32/32]: train_loss = 0.1309\n",
            "[Epoch 17/30 Iter    32/32]: train_loss = 0.1187\n",
            "[Epoch 18/30 Iter    32/32]: train_loss = 0.0920\n",
            "[Epoch 19/30 Iter    32/32]: train_loss = 0.0836\n",
            "[Epoch 20/30 Iter    32/32]: train_loss = 0.0660\n",
            "[Epoch 21/30 Iter    32/32]: train_loss = 0.0807\n",
            "[Epoch 22/30 Iter    32/32]: train_loss = 0.0765\n",
            "[Epoch 23/30 Iter    32/32]: train_loss = 0.0673\n",
            "[Epoch 24/30 Iter    32/32]: train_loss = 0.0713\n",
            "[Epoch 25/30 Iter    32/32]: train_loss = 0.0590\n",
            "[Epoch 26/30 Iter    32/32]: train_loss = 0.0502\n",
            "[Epoch 27/30 Iter    32/32]: train_loss = 0.0862\n",
            "[Epoch 28/30 Iter    32/32]: train_loss = 0.0516\n",
            "[Epoch 29/30 Iter    32/32]: train_loss = 0.0469\n",
            "[Epoch 30/30 Iter    32/32]: train_loss = 0.0932\n"
          ]
        }
      ],
      "source": [
        "history4 = train(net4, num_epochs=30, lr=0.01, momentum=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428Jjhmi-dbM"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "JdLliUfd-dbO",
        "outputId": "219b5ad3-d7a0-422b-c2e2-d63a30ba69cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 78.00%\n"
          ]
        }
      ],
      "source": [
        "evaluate(net4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlIhET9P-dbR"
      },
      "source": [
        "## 3 Compare the Training Loss\n",
        "\n",
        "Lastly, let's plot the training loss history for each of the training schemes for simple comparison:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "l0Nq76zy-dbR",
        "outputId": "4a027f1a-8183-4c7a-cece-2571ff4d7702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history1, label='From scratch')\n",
        "plt.plot(history2, label='Finetuning the pretrained model')\n",
        "plt.plot(history3, label='Finetuning the fc layer')\n",
        "plt.plot(history4, label='Finetuning the top few layers')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZIKznqu-dbU"
      },
      "source": [
        "---\n",
        "#<center>- End of P07 -\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}