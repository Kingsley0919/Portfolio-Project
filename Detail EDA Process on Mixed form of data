# -*- coding: utf-8 -*-
"""
Created on Mon Jan 22 22:20:28 2024

@author: kingsley
"""
# =============================================================================
# Inspect the information about the dataset, ensure the data type is correct,
# check for the missing value, and making sure the dataset is read properly
# =============================================================================

#Import the necessary library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math
from scipy import stats

#Read the data set
df = pd.read_csv(r'C:\Users\User\Desktop\world food production.csv')

# Display the first five rows of the dataset
print("First five rows of the dataset:")
print(df.head())

print("\nInformation about the dataset:")
print(df.info())


# Inspect the shape of the data (number of rows and columns)
print("\nShape of the dataset (rows, columns):")
print(df.shape)

# Print unique values of the first column ('Entity')
unique_entities = df['Entity'].unique()

# Print the number of unique value of the first column('Entity')
unique_count = df['Entity'].nunique()

print("Unique values of the 'Entity' column:")
print(unique_entities)
print("Number of Unique values of the 'Entity' column:")
print(unique_count)


# =============================================================================
# Second Step in a Data Science Pipeline, summarize the statistic for each column
# for each group, and identify the possible distribution of each column
# Check for the outlier.
# =============================================================================

# Display the basic statistic for each column
print(df.describe())

# List of columns with 'float64' and 'int64' data types
numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()


# Group the DataFrame by 'Entity' and calculate statistics for each group of entity in each column
entity_statistics = {}
for entity, group in df.groupby('Entity'):
    entity_statistics[entity] = {}
    for column in numeric_columns:
        entity_statistics[entity][column] = {
            "Minimum": np.min(group[column]),
            "Maximum": np.max(group[column]),
            "Mean": np.mean(group[column]),
            "Median": np.median(group[column]),
            "Standard Deviation": np.std(group[column])
        }

# Display the statistical summary for each entity for each numeric columns
for entity, stat in entity_statistics.items():
    print(f"\nStatistics for {entity}:")
    for column, stat_values in stats.items():
        print(f"Column: {column}")
        for stat_name, stat_value in stat_values.items():
            print(f"{stat_name}: {stat_value}")
            
            
            
## Inspect the distrirbution of the dataset, for each column
# Print the value counts of 'Entity' column in descending order
entity_count = df['Entity'].value_counts().sort_values(ascending=True)
print(entity_count)


# Initialize dictionaries to store statistics
mean_dict = {}
median_dict = {}
std_dict = {}
skewness_dict = {}


# Loop through numeric columns and create histograms with KDE plots
for i, column in enumerate(numeric_columns):
    
    # Calculate statistics for the whole column
    mean_dict[column] = df[column].mean()
    median_dict[column] = df[column].median()
    std_dict[column] = df[column].std()
    skewness_dict[column] = df[column].skew()
    
    # Print statistics
for column in numeric_columns:
    print(f"Statistics for {column}:")
    print(f"Mean: {mean_dict[column]}")
    print(f"Median: {median_dict[column]}")
    print(f"Standard Deviation: {std_dict[column]}")
    print(f"Skewness: {skewness_dict[column]}")
    

## Inpect the maximum and meanimum production of entity for each food production in each year
# Selecting all columns from the third to the last for food products 
food_products = df.columns[2:]
results = []

# Iterate through each food product
for product in food_products:
    # Group by year and find the entity with max and min production
    for year, group in df.groupby('Year'):
        max_entity = group[group[product] == group[product].max()]['Entity'].iloc[0]
        min_entity = group[group[product] == group[product].min()]['Entity'].iloc[0]
        results.append({
            'Year': year,
            'Product': product,
            'Max Entity': max_entity,
            'Min Entity': min_entity
        })


# Convert results to a DataFrame for better visualization
results_df = pd.DataFrame(results)
print(results_df)



# =============================================================================
# Function to create histogram and kde plots for a subset of columns to inspect the distribution of each 
# column and to create boxplot to check for outlier in each column.
# =============================================================================
def create_plots(columns_subset, set_number, plot_type):
    num_columns = 2  # Number of columns in each row
    num_rows = math.ceil(len(columns_subset) / num_columns)  # Number of rows

    # Create subplots for the current subset
    fig, axes = plt.subplots(num_rows, num_columns, figsize=(12, 6))
    fig.suptitle(f'{plot_type.capitalize()}s Set {set_number}')

    # Loop through the subset of columns
    for i, column in enumerate(columns_subset):
        row = i // num_columns
        col = i % num_columns
        ax = axes[row, col]

        # Create the specified type of plot
        if plot_type == 'boxplot':
            sns.boxplot(data=df, y=column, ax=ax)
        elif plot_type == 'histplot':
            sns.histplot(df[column], bins=30, kde=True, ax=ax)

        # Set labels and title
        ax.set_ylabel('Value' if plot_type == 'boxplot' else 'Count')
        ax.set_title(f'{plot_type.capitalize()} of {column}')

    # Adjust layout and remove empty subplots if any
    for i in range(len(columns_subset), num_rows * num_columns):
        fig.delaxes(axes.flatten()[i])
    plt.tight_layout()
    plt.show()

# Split the numeric columns into three groups
group1 = numeric_columns[:8]
group2 = numeric_columns[8:16]
group3 = numeric_columns[16:]

# Example usage
create_plots(group1, 1, 'boxplot') 
create_plots(group2, 2, 'boxplot')   
create_plots(group3, 3, 'boxplot') 
 
create_plots(group1, 1, 'histplot') 
create_plots(group2, 2, 'histplot')
create_plots(group3, 3, 'histplot') 



# Define a function to detect outliers and print the percentage of outliers
def detect_outliers_with_zscore(dataframe, columns):
    outlier_percentages = {}
    
    for column in columns:
        # Calculate the z-score
        z_scores = stats.zscore(dataframe[column])
        
        # Identify outliers
        outliers = np.where(np.abs(z_scores) > 3)  # typically, a z-score above 3 is considered an outlier
        
        # Calculate the percentage of outliers
        total_values = len(dataframe[column])
        percentage = len(outliers[0]) / total_values * 100
        
        # Store the percentage of outliers
        outlier_percentages[column] = percentage
        
        # Print the percentage of outliers
        print(f"Percentage of outliers in {column}: {percentage:.2f}%")
        
        # You can also choose to print or store the actual outlier values
        # print(f"Outliers in {column}:", dataframe.iloc[outliers][column].values)
        
    return outlier_percentages

# Call the function
outliers_percentages = detect_outliers_with_zscore(df, numeric_columns)





# =============================================================================
# Analyze on Year Time Series data, to see the production of each categpry of product
# in each year
# =============================================================================
# Select numeric columns (excluding 'Year')
numeric_columns_year = df.select_dtypes(include=['float64', 'int64']).columns.drop('Year')

# Group by 'Year' and sum the numeric columns
yearly_sum = df.groupby('Year')[numeric_columns_year].sum().reset_index()

# Determine the layout of the subplots
num_cols = len(numeric_columns_year)
n_rows = (num_cols + 1) // 2  # Adjust the number of rows as needed
n_cols = 2 if num_cols > 1 else 1

# Create a figure and axes for the subplots
fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 10, n_rows * 6))

# Flatten the axes array for easy iteration
axs = axs.flatten()

# Plotting regression graphs in subplots
for i, col in enumerate(numeric_columns_year):
    sns.regplot(x='Year', y=col, data=yearly_sum, ax=axs[i])
    axs[i].set_title(f'Regression of {col} over Years')
    axs[i].set_ylabel(f'Sum of {col}')
    axs[i].set_xlabel('Year')

# Adjust layout and show plot
plt.tight_layout()
plt.show()



## Inspect their relationship, to see which product production will produce according t other product
# Calculate the correlation matrix between numeric columns
correlation_matrix = yearly_sum.corr()

# Create a heatmap to visualize the correlations
plt.figure(figsize=(12, 8))
sns.set(font_scale=1)  # Adjust font size for labels

# Create the heatmap with adjusted font size
heatmap = sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f",
                      linewidths=0.5, square=True, cbar=True, vmin=-1, vmax=1)

# Adjust font size for values inside the cells
for text in heatmap.texts:
    text.set_fontsize(8)  # Set the desired font size for cell values

# Set title
plt.title("Correlation Heatmap of Numeric Columns by Year")

# Show the plot
plt.show()







